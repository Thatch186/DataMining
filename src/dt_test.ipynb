{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'decision_tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdecision_tree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTree\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdataset\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'decision_tree'"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decision_tree import DecisionTree\n",
    "import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset: Dataset, test_size=0.3):\n",
    "    nrows = dataset.get_X().shape[0]\n",
    "    test_size = int(test_size * nrows)\n",
    "    train_size = nrows - test_size\n",
    "    idx = np.arange(nrows)\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:train_size]\n",
    "    test_idx = idx[train_size:]\n",
    "\n",
    "    # Get the X and Y attributes of the dataset object\n",
    "    X = dataset.get_X()\n",
    "    y = dataset.get_y()\n",
    "    features = dataset.get_features()\n",
    "    label = dataset.get_label()\n",
    "\n",
    "    # Split the X and Y data into training and test sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # Define the discrete and numeric features\n",
    "    data = pd.DataFrame(X)\n",
    "    discretes = [str(col) for col in data.columns if data[col].dtype in ['object', 'category', 'bool']]\n",
    "\n",
    "    # Create the training and test datasets\n",
    "    train = Dataset(X=X_train, y=y_train, features=features, discrete_features = discretes, label=label)\n",
    "    test = Dataset(X=X_test, y=y_test, features=features, discrete_features = discretes, label=label)\n",
    " \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dt():\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    dataset_name = \"breast-bin.data\"\n",
    "    print(\"\\033[93m{}\\033[00m\".format(f\"Lendo Dataset {dataset_name}\"))\n",
    "    ds = read_csv(f\"../datasets/{dataset_name}\", ',',features=False,label=True)\n",
    "    print(\"Leitura completa.\\n\")\n",
    "    ds.replace_nulls()\n",
    "\n",
    "    print(\"\\033[93m{}\\033[00m\".format(f\"Dividindo dataset: {dataset_name}\\n\"))\n",
    "    train_data, test_data = train_test_split(ds)\n",
    "    print(f\"Shape of train data [X_train]: ({train_data.get_X().shape[0]},{train_data.get_X().shape[1]})\")\n",
    "    print(f\"Shape of test data   [X_test]: ({test_data.get_X().shape[0]},{test_data.get_X().shape[1]})\")\n",
    "\n",
    "    print(\"\\033[93m{}\\033[00m\".format(f\"\\nAplicando DT ...\\n\"))\n",
    "\n",
    "    dt = DecisionTree(criterion='entropy', # criterion: {'gini' (default), 'entropy', 'loss'}\n",
    "                       prun='post',         # prun: {'pre' (default), 'post'}\n",
    "                       max_depth=7, \n",
    "                       min_samples_leaf=2, \n",
    "                       min_samples_split=3, \n",
    "                       x_test=test_data.get_X(), \n",
    "                       y_test=test_data.get_y())\n",
    "\n",
    "    dt.fit(train_data)\n",
    "    y_pred = dt.predict(test_data.get_X())\n",
    "    y_true = test_data.get_y()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy: %4f\" % acc)\n",
    "    print(\"=\"*65 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c54ff1b262ec793716ebe3cd199d0dd4554fe9695ec96ceed4d094d21ae66a9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
